---
title: "Data analysis code"
author: Erick E. Mollinedo
date: '`r format(Sys.Date(), "%B %d, %Y")`'
format: html
editor: visual
---

## Data Analysis

List of packages needed for the whole data processing and data analysis

```{r}
library(here)
library(readxl)
library(tidyverse)
library(corrplot)
library(grid)
library(RColorBrewer)
library(ggpubr)
library(rstatix)
library(tidymodels)
```

Open the `concentration` and `hapin_samples` .RDS files to conduct the analyses.

```{r}
concentration <- read_rds(here("data", "processed-data", "concentration.rds"))
hapin_filters <- read_rds(here("data", "processed-data", "hapin_samples.rds"))
```

### Summarize Concentrations

The following chunk of code is to create the descriptive statistics tables for all chemical species concentrations. The tables will be saves as RDS files, so later they can be loaded as tables using `gt()`.

```{r}
#Create data frames for both LPG and Biomass groups
biomass <- concentration %>% filter(fueltype == "Biomass") %>% select(-c(arm, filter_id))
lpg <- concentration %>% filter(fueltype == "LPG") %>% select(-c(arm, filter_id))

#Format dfs longer
biomass_long <- biomass %>% #Biomass dataframe
  pivot_longer(cols = -fueltype,
               names_to = "Species", values_to = "Concentration")

lpg_long <- lpg %>% #LPG dataframe
  pivot_longer(cols = -fueltype,
               names_to = "Species", values_to = "Concentration")

#Create summary tables for each group
biomass_summary <- biomass_long %>% #Biomass fuel
  group_by(Species) %>% 
  summarise(N = n(),
            Mean = round(mean(Concentration), 2),
            SD = round(sd(Concentration), 2),
            Median = round(median(Concentration), 2),
            IQR = round(IQR(Concentration), 2),
            Min = round(min(Concentration), 2),
            Max = round(max(Concentration), 2))

lpg_summary <- lpg_long %>% #LPG fuel
  group_by(Species) %>% 
  summarise(N = n(),
            Mean = round(mean(Concentration), 2),
            SD = round(sd(Concentration), 2),
            Median = round(median(Concentration), 2),
            IQR = round(IQR(Concentration), 2),
            Min = round(min(Concentration), 2),
            Max = round(max(Concentration), 2))

#Save dataframes in RDS format so they can later be uploaded as tables
write_rds(biomass_summary, here("results", "tables", "biomass-summary.rds"))
write_rds(lpg_summary, here("results", "tables", "lpg-summary.rds"))
```

### Correlations

To answer the first question (correlations by species), I will plot the correlations in a correlation plot using the `corrplot()` function. I used the previous code, since it was already developed, but editing to add more detail to the plot.

```{r}
#First, delete unnecessary variables to conduct the correlation test
cor <- concentration %>% select(-c(filter_id, fueltype, arm))

#Perform the spearman correlation test
cor <- stats::cor(cor, method = "pearson")

#Create the correlation plot
corrplot(cor, method = "color", type = "lower", #Color form and displays at the lower portion
         col = COL2("RdYlBu", 20), order = "hclust", #Color palette, and order or the species
         tl.col = "orangered4", tl.srt = 0, tl.cex = 1,  #Color of the axis, position and size
         addCoef.col = "gray10", number.font = 2, number.cex = 0.8, #Display correlation number, set the font and size
         col.lim = c(0, 1), is.corr = T) #Set the color limits at the bar
```

### Fuel type contrasts

To answer question 2 (species differences among type of fuel), I will conduct a T-test using the `tidymodels` package

```{r}
# Conduct T-tests for the chemical species based on 'fueltype'
results <- map_dfr(2:12, function(i) { #To select columns that contain the variables to analyze
  variable <- names(concentration)[i] #The dataframe where the name of the variables are
  t_test <- t.test(reformulate('fueltype', response = variable), data = concentration) #Select the fueltype variable
  
  tibble( #Format the tibble
    variable = variable,
    statistic = t_test$statistic,
    p_value = t_test$p.value,
    estimate = t_test$estimate,
    null_value = t_test$null.value,
    alternative = t_test$alternative,
    method = t_test$method,
    conf_low = t_test$conf.int[1],
    conf_high = t_test$conf.int[2])
})

results #Print the results as a tibble
```

To see a graphical representation of this test, check the boxplots generated in the `data_exploring_code.qmd` file.

### PM2.5 and BC Modeling

To answer questions 3 and 4 (modeling between PM2.5, BC and other chemical species), I will conduct a regression analysis. But first I will merge the data from `hapin_filters` with the `concentration` data. Modeling can be difficult if there are missing values, so I will additionally clean the `hapin_merged` df, so it removes all NAs.

```{r}
#remove the 'arm' and 'fueltype' variables from the 'concentration' df
conc2 <- concentration %>% select(-c(arm, fueltype))

#Use 'inner_join()' to merge dataframes
hapin_merged <- inner_join(conc2, hapin_filters, by= "filter_id")

#Remove bc and co, and additionally drop all NAs
hapin_merged <- hapin_merged %>%
  select(-c(bc, co)) %>%
  drop_na()

#Save new df as a .RDS file
saveRDS(hapin_merged, file = here("data", "processed-data", "hapin-final.rds"))
```

Now conducting the model selection using the `tidymodels` package. For the models, I tried two multivariate models, first, using the gamma distribution family, since the concentrations of each chemical species could be explained by the gamma distribution. And the second model, using a simple linear regression. Also, the data was split into training (80%) and test data (20%).

```{r}
# Split the data into training and testing sets
rngseed = 1234
set.seed(rngseed) # for reproducibility
data_split <- initial_split(hapin_merged, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)
```

Now, creating the formulas for each question. Also, computing the model specifications, the workflow and fitting the models

```{r}
#Create formulas
pm25formula <- pm25 ~ Mg + Al + Si + S + K + Ca + Ti + Mn + Fe + Zn + BC
bcformula <- BC ~ smoke + coil + trash + kerosene + smoky + crop + stove_other + fueltype

#Set model specifications
lin_mod <- linear_reg() %>% set_engine("lm") #Linear
glm_mod <- linear_reg(mode = "regression") %>% #GLM gamma
  set_engine("glm", family = Gamma(link = "log"))

## ----Model 1: PM2.5 Linear---- ##
linpm_wflow <- workflow() %>% #Workflow
	add_model(lin_mod) %>% 
	add_formula(pm25formula)

linpm_fit <- linpm_wflow %>% fit(data = train_data) #Fit the model

## ----Model 2: PM2.5 GLM Gamma---- ##
glmpm_wflow <- workflow() %>% #Workflow
  add_model(glm_mod) %>% 
  add_formula(pm25formula)

glmpm_fit <- glmpm_wflow %>% fit(data = train_data) #Fit the model

## ----Model 3: BC Linear---- ##
linbc_wflow <- workflow() %>% #Workflow
	add_model(lin_mod) %>% 
	add_formula(bcformula)

linbc_fit <- linbc_wflow %>% fit(data = train_data) #Fit the model

## ----Model 4: BC GLM Gamma---- ##
glmbc_wflow <- workflow() %>% #Workflow
  add_model(glm_mod) %>% 
  add_formula(bcformula)

glmbc_fit <- glmbc_wflow %>% fit(data = train_data) #Fit the model
```

Extracting the results from each model.

```{r}
# Extract and print the results of the models
results_pmlin <- linpm_fit %>% #PM2.5 Linear
  extract_fit_parsnip() %>%
  tidy()

results_pmglm <- glmpm_fit %>% #PM2.5 GLM
  extract_fit_parsnip() %>%
  tidy()

results_bclin <- linbc_fit %>% #BC Linear
  extract_fit_parsnip() %>%
  tidy()

results_bcglm <- glmbc_fit %>% #BC GLM
  extract_fit_parsnip() %>%
  tidy()

#Print the results
print(results_pmlin)
print(results_pmglm)
print(results_bclin)
print(results_bcglm)
```

Now, doing an evaluation of each model First, by estimating the metrics (In this case I will use RMSE, R-squared and MAE). First computing the predictions to make comparisons with the observed values.

```{r}
#Compute the predictions
#PM2.5 models
lin_pm_pred <- linpm_fit %>% predict(train_data)
glm_pm_pred <- glmpm_fit %>% predict(train_data)
#BC models
lin_bc_pred <- linbc_fit %>% predict(train_data)
glm_bc_pred <- glmbc_fit %>% predict(train_data)

#Compute the metrics
#PM2.5 models
lin_pm_metrics <-  bind_cols(train_data, lin_pm_pred) %>% metrics(truth = pm25, estimate = .pred) 
glm_pm_metrics <- bind_cols(train_data, glm_pm_pred) %>% metrics(truth = pm25, estimate = .pred)
#BC Models
lin_bc_metrics <-  bind_cols(train_data, lin_bc_pred) %>% metrics(truth = BC, estimate = .pred) 
glm_bc_metrics <- bind_cols(train_data, glm_bc_pred) %>% metrics(truth = BC, estimate = .pred)

#Print the metrics
print(lin_pm_metrics)
print(glm_pm_metrics)
print(lin_bc_metrics)
print(glm_bc_metrics)
```

Continue the model evaluation, plotting the observed vs predicted values for each model.

```{r}
#Create dataframes to compute the plots
#PM2.5
pred_pm1 <- data.frame(predicted = lin_pm_pred$.pred, model = "linear")
pred_pm2 <- data.frame(predicted = glm_pm_pred$.pred, model = "GLM")
#BC
pred_bc1 <- data.frame(predicted = lin_bc_pred$.pred, model = "linear")
pred_bc2 <- data.frame(predicted = glm_bc_pred$.pred, model = "GLM")

#Merge data frames
#PM2.5
pmdata_plot <- bind_rows(pred_pm1, pred_pm2) %>% 
  mutate(observed = rep(train_data$pm25, 2))
#BC
bcdata_plot <- bind_rows(pred_bc1, pred_bc2) %>% 
  mutate(observed = rep(train_data$BC, 2))

#Create pred-obs plot

#Define colors
my_colors <- c("GLM" = "#E1BE6A", "linear" = "#40B0A6")

#PM2.5
pmpreds <- ggplot(pmdata_plot) +
  geom_point(aes(x = observed, y = predicted, color= model), size= 2) +
  facet_wrap(~ model)+
  scale_color_manual(values = my_colors)+
  labs(x = "Observed", y = "Predicted") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  theme_bw()

#BC
bcpreds <- ggplot(bcdata_plot) +
  geom_point(aes(x = observed, y = predicted, color= model), size= 2) +
  facet_wrap(~ model)+
  scale_color_manual(values = my_colors)+
  labs(x = "Observed", y = "Predicted") +
  theme_bw()

#Visualize plots
pmpreds
bcpreds

#Save plots
ggsave(here("results", "figures", "obs-pred_pm25.png"), plot = pmpreds, width = 10, height = 6, dpi = 300)
ggsave(here("results", "figures", "obs-pred_bc.png"), plot = bcpreds, width = 10, height = 6, dpi = 300)
```

Also, computing the residuals for each model and plotting them.

```{r}
#Calculate residuals and create data frame
#PM2.5
pmdata_plot <- pmdata_plot %>% mutate(observation = 1:988, residuals = observed - predicted)
#BC
bcdata_plot <- bcdata_plot %>% mutate(observation = 1:988, residuals = observed - predicted)

# Plot residuals using ggplot
#PM2.5
pmresiduals <- ggplot(pmdata_plot) +
  geom_point(aes(x = observation, y = residuals, color= model), size= 2) +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", color = "black") +
  scale_color_manual(values = my_colors)+
  labs(x = "Data point",
       y = "Residuals")+
  theme_bw()

#BC
bcresiduals <- ggplot(bcdata_plot) +
  geom_point(aes(x = observation, y = residuals, color= model), size= 2) +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", color = "black") +
  scale_color_manual(values = my_colors)+
  labs(x = "Data point",
       y = "Residuals")+
  theme_bw()

#Visualize plots
pmresiduals
bcresiduals

#Save plots
ggsave(here("results", "figures", "residuals-pm25.png"), plot = pmresiduals, width = 10, height = 6, dpi = 300)
ggsave(here("results", "figures", "residuals-bc.png"), plot = bcresiduals, width = 10, height = 6, dpi = 300)
```

And then computing the 90% confidence intervals for the predicted values for each model.

```{r}
## ----Model 1: PM2.5 Linear---- ##
# Compute prediction intervals
pred_int_linpm <- predict(linpm_fit, train_data, type = "conf_int", level = 0.90) %>%
  mutate(observation = 1:494)

# Combine the lower and upper bounds with the observed values
pred_int_linpm <- cbind(lin_pm_pred, pred_int_linpm, train_data$pm25)
pred_int_linpm <- pred_int_linpm %>% rename(observed = "train_data$pm25")
```

Finally, plotting the predictions and the prediction intervals.

```{r}
#Prediction interval plot for the linear model of PM2.5
ggplot(pred_int_linpm) +
	geom_errorbar(aes(x = observed, ymin = .pred_lower, ymax = .pred_upper), width = 25) +
	geom_point(aes(x = observed, y = .pred, color = ".pred"),	shape = 5) +
	labs(x = "Observed", y = "Predicted", title = "Predicted observation with Prediction Intervals") +
	geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
	scale_color_manual(values = my_colors) +
	theme_minimal()
```

This plot looks crowded for the linear model, so I won't use it as part of the final assessment of this and the other models. However I will keep it for future references.

Then, doing a final evaluation of the model using the test data. I decided to select the linear multivariate models for both models (PM2.5 and BC).

```{r}
## ----PM2.5 Linear---- ##
#Fit the model using the test data
linpm_fit_test <- linpm_wflow %>% fit(data = test_data)

#Make predictions in the test data
pm_preds2 <- linpm_fit_test %>% predict(test_data)

#Compute the metrics
linpm_metrics_test <- bind_cols(test_data, pm_preds2) %>% metrics(truth = pm25, estimate = .pred)

print(linpm_metrics_test)

## ----BC Linear---- ##
#Fit the model using the test data
linbc_fit_test <- linbc_wflow %>% fit(data = test_data)

#Make predictions in the test data
bc_preds2 <- linbc_fit_test %>% predict(test_data)

#Compute the metrics
linbc_metrics_test <- bind_cols(test_data, bc_preds2) %>% metrics(truth = BC, estimate = .pred)

print(linbc_metrics_test)
```

### Save outputs as tables

Creating a table to save all the metric values in one table. First creating new dataframes that includes all metrics for the PM2.5 and BC models.

```{r}
#Bind dfs that contain all RMSEs and R-squares from the PM2.5 and BC models
metricspm_final <- bind_rows(lin_pm_metrics, glm_pm_metrics)
metricsbc_final <- bind_rows(lin_bc_metrics, glm_bc_metrics)

#Delete non-necessary columns
metricspm_final <- metricspm_final %>% select(-.estimator)
metricsbc_final <- metricsbc_final %>% select(-.estimator)

# Creating a vector of observation types
obs <- rep(c(rep("M1", 3), rep("M2", 3)), length.out = 6)

# Adding the 'obs' variable to 'metrics_final'
metricspm_final$obs <- obs
metricsbc_final$obs <- obs
```

Do additional adjustments to the metrics table, and then save it as an .RDS file.

```{r}
#Change dataframe from long to wide
metricspm_wide <- metricspm_final %>% pivot_wider(names_from = obs, values_from = .estimate)
metricsbc_wide <- metricsbc_final %>% pivot_wider(names_from = obs, values_from = .estimate)

#Rename columns, rearrange them and edit values for some columns
metricspm_wide <- metricspm_wide %>% 
  rename(Metric = ".metric", Linear = "M1", GLM = "M2") %>% 
  mutate(Metric = case_when(Metric == "rmse" ~ "RMSE",
                            Metric == "rsq" ~ "R-squared",
                            Metric == "mae" ~ "MAE", TRUE ~ Metric))

metricsbc_wide <- metricsbc_wide %>% 
  rename(Metric = ".metric", Linear = "M1", GLM = "M2") %>% 
  mutate(Metric = case_when(Metric == "rmse" ~ "RMSE",
                            Metric == "rsq" ~ "R-squared",
                            Metric == "mae" ~ "MAE", TRUE ~ Metric))


#Save df as .RDS file
saveRDS(metricspm_wide, file = here("results", "tables", "pmmodel_metrics.rds"))
saveRDS(metricsbc_wide, file = here("results", "tables", "bcmodel_metrics.rds"))
```
